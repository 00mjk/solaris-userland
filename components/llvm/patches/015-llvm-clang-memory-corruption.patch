# Memory corruption in LLVM.
# https://llvm.org/bugs/show_bug.cgi?id=24607
--- include/llvm/ADT/DenseMap.h	2014-12-06 14:22:44.000000000 -0500
+++ include/llvm/ADT/DenseMap.h	2015-08-25 21:45:36.712994054 -0400
@@ -254,7 +254,7 @@
   DenseMapBase() {}
 
   void destroyAll() {
-    if (getNumBuckets() == 0) // Nothing to do.
+    if ((getNumBuckets() == 0) || empty()) // Nothing to do.
       return;
 
     const KeyT EmptyKey = getEmptyKey(), TombstoneKey = getTombstoneKey();
--- include/llvm/IR/Attributes.h	2014-09-03 19:38:05.000000000 -0400
+++ include/llvm/IR/Attributes.h	2015-08-25 11:24:38.160033797 -0400
@@ -406,18 +406,27 @@
   uint64_t Alignment;
   uint64_t StackAlignment;
   uint64_t DerefBytes;
+
 public:
-  AttrBuilder() : Attrs(0), Alignment(0), StackAlignment(0), DerefBytes(0) {}
+  AttrBuilder() : Attrs(0), TargetDepAttrs(), Alignment(0),
+  StackAlignment(0), DerefBytes(0) {}
+
   explicit AttrBuilder(uint64_t Val)
-    : Attrs(0), Alignment(0), StackAlignment(0), DerefBytes(0) {
+    : Attrs(0), TargetDepAttrs(), Alignment(0),
+    StackAlignment(0), DerefBytes(0) {
     addRawValue(Val);
   }
+
   AttrBuilder(const Attribute &A)
-    : Attrs(0), Alignment(0), StackAlignment(0), DerefBytes(0) {
+    : Attrs(0), TargetDepAttrs(), Alignment(0), StackAlignment(0),
+    DerefBytes (0) {
     addAttribute(A);
   }
+
   AttrBuilder(AttributeSet AS, unsigned Idx);
 
+  ~AttrBuilder() { }
+
   void clear();
 
   /// \brief Add an attribute to the builder.
--- include/llvm/IR/Metadata.h	2015-02-08 19:35:35.000000000 -0800
+++ include/llvm/IR/Metadata.h	2015-08-26 21:27:54.937575563 -0700
@@ -24,6 +24,7 @@
 #include "llvm/IR/MetadataTracking.h"
 #include "llvm/IR/Value.h"
 #include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
 #include <type_traits>
 
 namespace llvm {
@@ -42,13 +43,15 @@
 /// This is a root class for typeless data in the IR.
 class Metadata {
   friend class ReplaceableMetadataImpl;
+  friend class MDNode;
 
   /// \brief RTTI.
   const unsigned char SubclassID;
 
 protected:
   /// \brief Storage flag for non-uniqued, otherwise unowned, metadata.
-  bool IsDistinctInContext : 1;
+  bool IsDistinctInContext;
+
   // TODO: expose remaining bits to subclasses.
 
   unsigned short SubclassData16;
@@ -149,7 +152,7 @@
   SmallDenseMap<void *, std::pair<OwnerTy, uint64_t>, 4> UseMap;
 
 public:
-  ReplaceableMetadataImpl() : NextIndex(0) {}
+  ReplaceableMetadataImpl() : NextIndex(0), UseMap() {}
   ~ReplaceableMetadataImpl() {
     assert(UseMap.empty() && "Cannot destroy in-use replaceable metadata");
   }
@@ -583,9 +586,11 @@
 //===----------------------------------------------------------------------===//
 /// \brief Tuple of metadata.
 class MDNode : public Metadata {
+  friend class MDNodeFwdDecl;
+  friend class MDTuple;
+
   MDNode(const MDNode &) LLVM_DELETED_FUNCTION;
   void operator=(const MDNode &) LLVM_DELETED_FUNCTION;
-  void *operator new(size_t) LLVM_DELETED_FUNCTION;
 
   LLVMContext &Context;
   unsigned NumOperands;
@@ -593,17 +598,21 @@
 protected:
   unsigned MDNodeSubclassData;
 
-  void *operator new(size_t Size, unsigned NumOps);
-  void operator delete(void *Mem);
+  static void *operator new(size_t Size, unsigned NumOps) throw();
+  static void operator delete(void *Mem) throw();
 
   /// \brief Required by std, but never called.
-  void operator delete(void *, unsigned) {
-    llvm_unreachable("Constructor throws?");
+  static void operator delete(void *, unsigned) {
+    llvm::errs() << __PRETTY_FUNCTION__
+      << ": This should never be called!\n";
+    abort();
   }
 
   /// \brief Required by std, but never called.
-  void operator delete(void *, unsigned, bool) {
-    llvm_unreachable("Constructor throws?");
+  static void operator delete(void *, unsigned, bool) {
+    llvm::errs() << __PRETTY_FUNCTION__
+      << ": This should never be called!\n";
+    abort();
   }
 
   MDNode(LLVMContext &Context, unsigned ID, ArrayRef<Metadata *> MDs);
@@ -715,6 +724,8 @@
 class UniquableMDNode : public MDNode {
   friend class ReplaceableMetadataImpl;
   friend class MDNode;
+  friend class MDTuple;
+  friend class MDLocation;
   friend class LLVMContextImpl;
 
   /// \brief Support RAUW as long as one of its arguments is replaceable.
@@ -796,10 +807,14 @@
   static MDTuple *get(LLVMContext &Context, ArrayRef<Metadata *> MDs) {
     return getImpl(Context, MDs, /* ShouldCreate */ true);
   }
+
   static MDTuple *getIfExists(LLVMContext &Context, ArrayRef<Metadata *> MDs) {
     return getImpl(Context, MDs, /* ShouldCreate */ false);
   }
 
+  void *operator new(size_t Size, unsigned NumOps) throw();
+  void operator delete(void *Mem) throw();
+
   /// \brief Return a distinct node.
   ///
   /// Return a distinct node -- i.e., a node that is not uniqued.
@@ -847,6 +862,9 @@
   void replaceOperandWith(unsigned I, Metadata *New) LLVM_DELETED_FUNCTION;
 
 public:
+  void *operator new(size_t Size, unsigned NumOps) throw();
+  void operator delete(void* Mem) throw();
+
   static MDLocation *get(LLVMContext &Context, unsigned Line, unsigned Column,
                          Metadata *Scope, Metadata *InlinedAt = nullptr) {
     return getImpl(Context, Line, Column, Scope, InlinedAt,
@@ -885,18 +903,18 @@
 /// Forward declaration of metadata, in the form of a basic tuple.  Unlike \a
 /// MDTuple, this class has full support for RAUW, is not owned, is not
 /// uniqued, and is suitable for forward references.
-class MDNodeFwdDecl : public MDNode, ReplaceableMetadataImpl {
+class MDNodeFwdDecl : public MDNode, public ReplaceableMetadataImpl {
   friend class Metadata;
   friend class ReplaceableMetadataImpl;
 
   MDNodeFwdDecl(LLVMContext &C, ArrayRef<Metadata *> Vals)
-      : MDNode(C, MDNodeFwdDeclKind, Vals) {}
+  : MDNode(C, MDNodeFwdDeclKind, Vals), ReplaceableMetadataImpl() {}
 
 public:
   ~MDNodeFwdDecl() { dropAllReferences(); }
 
-  // MSVC doesn't see the alternative: "using MDNode::operator delete".
-  void operator delete(void *Mem) { MDNode::operator delete(Mem); }
+  void *operator new(size_t Size, unsigned NumOps) throw();
+  void operator delete(void *Mem) throw();
 
   static MDNodeFwdDecl *get(LLVMContext &Context, ArrayRef<Metadata *> MDs) {
     return new (MDs.size()) MDNodeFwdDecl(Context, MDs);
--- lib/IR/Attributes.cpp	2014-09-03 19:38:05.000000000 -0400
+++ lib/IR/Attributes.cpp	2015-08-26 00:21:40.551873740 -0400
@@ -1004,7 +1004,8 @@
 //===----------------------------------------------------------------------===//
 
 AttrBuilder::AttrBuilder(AttributeSet AS, unsigned Index)
-  : Attrs(0), Alignment(0), StackAlignment(0), DerefBytes(0) {
+  : Attrs(0), TargetDepAttrs(), Alignment(0),
+  StackAlignment(0), DerefBytes(0) {
   AttributeSetImpl *pImpl = AS.pImpl;
   if (!pImpl) return;
 
@@ -1052,7 +1053,9 @@
 }
 
 AttrBuilder &AttrBuilder::addAttribute(StringRef A, StringRef V) {
-  TargetDepAttrs[A] = V;
+  std::string AS = A.str();
+  std::string VS = V.str();
+  TargetDepAttrs[AS] = VS;
   return *this;
 }
 
@@ -1094,8 +1097,9 @@
         DerefBytes = 0;
     } else {
       assert(Attr.isStringAttribute() && "Invalid attribute type!");
-      std::map<std::string, std::string>::iterator
-        Iter = TargetDepAttrs.find(Attr.getKindAsString());
+      std::string AS = Attr.getKindAsString().str();
+      std::map<std::string, std::string>::iterator Iter =
+        TargetDepAttrs.find(AS);
       if (Iter != TargetDepAttrs.end())
         TargetDepAttrs.erase(Iter);
     }
@@ -1105,7 +1109,8 @@
 }
 
 AttrBuilder &AttrBuilder::removeAttribute(StringRef A) {
-  std::map<std::string, std::string>::iterator I = TargetDepAttrs.find(A);
+  std::map<std::string, std::string>::iterator I =
+    TargetDepAttrs.find(A.str());
   if (I != TargetDepAttrs.end())
     TargetDepAttrs.erase(I);
   return *this;
@@ -1163,7 +1168,7 @@
 }
 
 bool AttrBuilder::contains(StringRef A) const {
-  return TargetDepAttrs.find(A) != TargetDepAttrs.end();
+  return TargetDepAttrs.find(A.str()) != TargetDepAttrs.end();
 }
 
 bool AttrBuilder::hasAttributes() const {
@@ -1188,7 +1193,8 @@
         return true;
     } else {
       assert(Attr.isStringAttribute() && "Invalid attribute kind!");
-      return TargetDepAttrs.find(Attr.getKindAsString())!=TargetDepAttrs.end();
+      std::string AS = Attr.getKindAsString().str();
+      return TargetDepAttrs.find(AS) != TargetDepAttrs.end();
     }
   }
 
--- lib/IR/Metadata.cpp	2015-02-08 19:35:35.000000000 -0800
+++ lib/IR/Metadata.cpp	2015-08-28 23:18:08.062765258 -0700
@@ -379,24 +379,84 @@
 // MDNode implementation.
 //
 
-void *MDNode::operator new(size_t Size, unsigned NumOps) {
-  void *Ptr = ::operator new(Size + NumOps * sizeof(MDOperand));
-  MDOperand *O = static_cast<MDOperand *>(Ptr);
-  for (MDOperand *E = O + NumOps; O != E; ++O)
-    (void)new (O) MDOperand;
-  return O;
-}
+void *MDNode::operator new(size_t Size, unsigned NumOps) throw() {
+  assert((Size >= sizeof(MDNode)) && "Insufficient size to operator new!");
+
+  // MDNode wants to construct its ancillary MDOperands ** BEFORE **
+  // itself. 
+  //
+  // Allocate extra space for an uintptr_t at the beginning of the
+  // buffer.  This uintptr_t is where we will store the address of
+  // the memory-aligned storage buffer. It will be plasced immediately
+  // after the last MDOperand.
+  // This address will be computed by the matching operator delete.
+  // The total amount of space allocated must include the Size
+  // parameter passed in. This parameter value is not necessarily
+  // equal to sizeof(MDTuple), it can be greater.
+  std::size_t OSize = NumOps * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  std::size_t RSize = Size + OSize + sizeof(Metadata) + sizeof(uintptr_t);
+  RSize = RoundUpToAlignment(RSize, llvm::alignOf<uint64_t>());
+  std::size_t Alignment = llvm::alignOf<uint64_t>();
+
+  void *P;
+
+#if defined(_MSC_VER)
+  P = _aligned_malloc(RSize, Alignment);
+  assert(P && "_aligned_malloc failed!");
+  if (!P) return 0;
+#else
+  int R = posix_memalign(&P, Alignment, RSize);
+  assert((R == 0) && "posix_memalign failed!");
+  if (R != 0) return 0;
+#endif
+
+  (void) std::memset(P, 0, RSize);
+  unsigned char *UC = static_cast<unsigned char*>(P);
+  MDNode *MN = reinterpret_cast<MDNode*>((UC + RSize) - Size);
+
+  MDOperand *O = reinterpret_cast<MDOperand*>(MN);
+  MDOperand *MO;
+
+  for (MDOperand *E = O - NumOps; O != E; --O) {
+    MO = new (O - 1) MDOperand();
+    assert(MO && "MDOperand placement new failed!");
+  }
+
+  // We store the address of the aligned allocated buffer
+  // in the last extra element of the buffer. This address
+  // will be used by the corresponding operator delete to
+  // free the correct address.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+  *U = reinterpret_cast<uintptr_t>(P);
+  return MN;
+}
+
+void MDNode::operator delete(void *Mem) throw() {
+  MDNode *MN = reinterpret_cast<MDNode *>(Mem);
+  Metadata *MTD = static_cast<Metadata*>(MN);
+  std::size_t OSize = MN->NumOperands * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
 
-void MDNode::operator delete(void *Mem) {
-  MDNode *N = static_cast<MDNode *>(Mem);
   MDOperand *O = static_cast<MDOperand *>(Mem);
-  for (MDOperand *E = O - N->NumOperands; O != E; --O)
-    (O - 1)->~MDOperand();
-  ::operator delete(O);
+
+  for (MDOperand *E = O - MN->NumOperands; O != E; --O) {
+    MDOperand *MO = (O - 1);
+    MO->~MDOperand();
 }
 
-MDNode::MDNode(LLVMContext &Context, unsigned ID, ArrayRef<Metadata *> MDs)
-    : Metadata(ID), Context(Context), NumOperands(MDs.size()),
+  MTD->~Metadata();
+  MN->~MDNode();
+
+  // This is the address of the allocated buffer in the
+  // extra buffer space allocated by operator new.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+  std::free(reinterpret_cast<void*>(*U));
+}
+
+MDNode::MDNode(LLVMContext &Ctx, unsigned ID, ArrayRef<Metadata *> MDs)
+  : Metadata(ID), Context(Ctx), NumOperands(MDs.size()),
       MDNodeSubclassData(0) {
   for (unsigned I = 0, E = MDs.size(); I != E; ++I)
     setOperand(I, MDs[I]);
@@ -416,7 +476,7 @@
 
 UniquableMDNode::UniquableMDNode(LLVMContext &C, unsigned ID,
                                  ArrayRef<Metadata *> Vals, bool AllowRAUW)
-    : MDNode(C, ID, Vals) {
+  : MDNode(C, ID, Vals), ReplaceableUses() {
   if (!AllowRAUW)
     return;
 
@@ -428,7 +488,7 @@
   if (!NumUnresolved)
     return;
 
-  ReplaceableUses.reset(new ReplaceableMetadataImpl);
+  ReplaceableUses.reset(new ReplaceableMetadataImpl());
   SubclassData32 = NumUnresolved;
 }
 
@@ -577,6 +637,9 @@
     llvm_unreachable("Invalid subclass of UniquableMDNode");
 #define HANDLE_UNIQUABLE_LEAF(CLASS)                                           \
   case CLASS##Kind:                                                            \
+    static_assert(llvm::AlignOf<uint64_t>::Alignment >=             \
+        llvm::AlignOf<CLASS>::Alignment,                            \
+        "Insufficient alignment for objects prepended to " #CLASS); \
     delete cast<CLASS>(this);                                                  \
     break;
 #include "llvm/IR/Metadata.def"
@@ -589,6 +652,9 @@
     llvm_unreachable("Invalid subclass of UniquableMDNode");
 #define HANDLE_UNIQUABLE_LEAF(CLASS)                                           \
   case CLASS##Kind:                                                            \
+    static_assert(llvm::AlignOf<uint64_t>::Alignment >=             \
+        llvm::AlignOf<CLASS>::Alignment,                            \
+        "Insufficient alignment for objects prepended to " #CLASS); \
     return cast<CLASS>(this)->uniquifyImpl();
 #include "llvm/IR/Metadata.def"
   }
@@ -600,6 +666,9 @@
     llvm_unreachable("Invalid subclass of UniquableMDNode");
 #define HANDLE_UNIQUABLE_LEAF(CLASS)                                           \
   case CLASS##Kind:                                                            \
+    static_assert(llvm::AlignOf<uint64_t>::Alignment >=             \
+        llvm::AlignOf<CLASS>::Alignment,                            \
+        "Insufficient alignment for objects prepended to " #CLASS); \
     cast<CLASS>(this)->eraseFromStoreImpl();                                   \
     break;
 #include "llvm/IR/Metadata.def"
@@ -643,7 +712,91 @@
   return *I;
 }
 
-void MDTuple::eraseFromStoreImpl() { getContext().pImpl->MDTuples.erase(this); }
+void MDTuple::eraseFromStoreImpl() {
+  getContext().pImpl->MDTuples.erase(this);
+}
+
+void *MDTuple::operator new(size_t Size, unsigned NumOps) throw() {
+  assert((Size >= sizeof(MDTuple)) && "Insufficient size to operator new!");
+
+  std::size_t OSize = NumOps * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  // Allocate extra space for an uintptr_t at the beginning of the
+  // buffer.  This uintptr_t is where we will store the address of
+  // the memory-aligned storage buffer. It will be plasced immediately
+  // after the last MDOperand.
+  // This address will be computed by the matching operator delete.
+  // The total amount of space allocated must include the Size
+  // parameter passed in. This parameter value is not necessarily
+  // equal to sizeof(MDTuple), it can be greater.
+  std::size_t RSize = Size + OSize + sizeof(UniquableMDNode) +
+    sizeof(uintptr_t);
+  RSize = RoundUpToAlignment(RSize, llvm::alignOf<uint64_t>());
+  std::size_t Alignment = llvm::alignOf<uint64_t>();
+
+  void *P;
+
+#if defined(_MSC_VER)
+  P = _aligned_malloc(RSize, Alignment);
+  assert(P && "_aligned_malloc failed!");
+  if (!P) return 0;
+#else
+  int R = posix_memalign(&P, Alignment, RSize);
+  assert((R == 0) && "posix_memalign failed!");
+  if (R != 0) return 0;
+#endif
+
+  (void) std::memset(P, 0, RSize);
+
+  // Set a valid pointer to the address which will be returned
+  // by this operator. This will be a pointer to a MDTuple.
+  unsigned char *UC = static_cast<unsigned char*>(P);
+  MDTuple *MDT = reinterpret_cast<MDTuple*>((UC + RSize) - Size);
+  MDNode *MN = static_cast<MDNode*>(MDT);
+
+  MDOperand *O = reinterpret_cast<MDOperand*>(MN);
+  MDOperand *MO;
+
+  for (MDOperand *E = O - NumOps; O != E; --O) {
+    MO = new (O - 1) MDOperand();
+    assert(MO && "MDOperand placement new failed!");
+  }
+
+  // We store the address of the aligned allocated buffer
+  // in the last extra element of the buffer. This address
+  // will be used by the corresponding operator delete to
+  // free the correct address.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+  *U = reinterpret_cast<uintptr_t>(P);
+  return MDT;
+}
+
+void MDTuple::operator delete(void *Mem) throw() {
+  MDTuple *MDT = reinterpret_cast<MDTuple*>(Mem);
+  UniquableMDNode *UMN = static_cast<UniquableMDNode*>(MDT);
+  MDNode *MN = static_cast<MDNode*>(UMN);
+  unsigned NumOperands = MN->getNumOperands();
+
+  std::size_t OSize = NumOperands * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  MDOperand *O =
+    reinterpret_cast<MDOperand*>(reinterpret_cast<void*>(MN));
+  for (MDOperand *E = O - NumOperands; O != E; --O) {
+    MDOperand *MO = (O - 1);
+    MO->~MDOperand();
+  }
+
+  // This is teh address of the allocated buffer in the
+  // extra space allocated by operator new in RSize.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+
+  UMN->~UniquableMDNode();
+  MDT->~MDTuple();
+  std::free(reinterpret_cast<void*>(*U));
+}
+
 
 MDLocation::MDLocation(LLVMContext &C, unsigned Line, unsigned Column,
                        ArrayRef<Metadata *> MDs, bool AllowRAUW)
@@ -675,6 +828,88 @@
     Line = 0;
 }
 
+void *MDLocation::operator new(size_t Size, unsigned NumOps) throw() {
+  assert((Size >= sizeof(MDLocation)) && "Insufficient size to operator new!");
+
+  std::size_t OSize = NumOps * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  // Allocate extra space for an uintptr_t at the beginning of the
+  // buffer.  This uintptr_t is where we will store the address of
+  // the memory-aligned storage buffer. It will be plasced immediately
+  // after the last MDOperand.
+  // This address will be computed by the matching operator delete.
+  // The total amount of space allocated must include the Size
+  // parameter passed in. This parameter value is not necessarily
+  // equal to sizeof(MDLocation), it can be greater.
+  std::size_t RSize =
+    Size + OSize + sizeof(UniquableMDNode) + sizeof(uintptr_t);
+  RSize = RoundUpToAlignment(RSize, llvm::alignOf<uint64_t>());
+  std::size_t Alignment = llvm::alignOf<uint64_t>();
+
+  void *P;
+
+#if defined(_MSC_VER)
+  P = _aligned_malloc(RSize, Alignment);
+  assert(P && "_aligned_malloc failed!");
+  if (!P) return 0;
+#else
+  int R = posix_memalign(&P, Alignment, RSize);
+  assert((R == 0) && "posix_memalign failed!");
+  if (R != 0) return 0;
+#endif
+
+  (void) std::memset(P, 0, RSize);
+
+
+  // Set a valid pointer to the address which will be returned
+  // by this operator. This will be a pointer to a MDLocation.
+  unsigned char *UC = static_cast<unsigned char*>(P);
+  MDLocation *MDL = reinterpret_cast<MDLocation*>((UC + RSize) - Size);
+  MDNode *MN = static_cast<MDNode*>(MDL);
+
+  MDOperand *O = reinterpret_cast<MDOperand*>(MN);
+  MDOperand *MO;
+
+  for (MDOperand *E = O - NumOps; O != E; --O) {
+    MO = new (O - 1) MDOperand();
+    assert(MO && "MDOperand placement new failed!");
+  }
+
+  // We store the address of the aligned allocated buffer
+  // in the last extra element of the buffer. This address
+  // will be used by the corresponding operator delete to
+  // free the correct address.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+  *U = reinterpret_cast<uintptr_t>(P);
+  return MDL;
+}
+
+void MDLocation::operator delete(void *Mem) throw() {
+  MDLocation *MDL = reinterpret_cast<MDLocation*>(Mem);
+  UniquableMDNode *UMN = static_cast<UniquableMDNode*>(MDL);
+  MDNode *MN = static_cast<MDNode*>(UMN);
+  unsigned NumOperands = MN->getNumOperands();
+
+  std::size_t OSize = NumOperands * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  MDOperand *O =
+    reinterpret_cast<MDOperand*>(reinterpret_cast<void*>(MN));
+  for (MDOperand *E = O - NumOperands; O != E; --O) {
+    MDOperand *MO = (O - 1);
+    MO->~MDOperand();
+  }
+
+  // This is the address of the allocated buffer in the
+  // extra space allocated by operator new in RSize.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+
+  MDL->~MDLocation();
+  UMN->~UniquableMDNode();
+  std::free(reinterpret_cast<void*>(*U));
+}
+
 static void adjustColumn(unsigned &Column) {
   // Set to unknown on overflow.  Still use 8 bits for now.
   if (Column >= (1u << 8))
@@ -969,6 +1204,96 @@
 }
 
 //===----------------------------------------------------------------------===//
+// MDNodeFwdDecl implementation.
+//
+
+void *MDNodeFwdDecl::operator new(size_t Size, unsigned NumOps) throw() {
+  assert((Size >= sizeof(MDNodeFwdDecl)) && "Insufficient space to operator new!");
+
+  std::size_t OSize = NumOps * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  // Allocate extra space for an uintptr_t at the beginning of the
+  // buffer.  This uintptr_t is where we will store the address of
+  // the memory-aligned storage buffer. It will be plasced immediately
+  // after the last MDOperand.
+  // This address will be computed by the matching operator delete.
+  // The total amount of space allocated must include the Size
+  // parameter passed in. This parameter value is not necessarily
+  // equal to sizeof(MDTuple), it can be greater.
+  std::size_t RSize =
+    Size +  OSize + sizeof(MDNode) + sizeof(ReplaceableMetadataImpl) +
+    sizeof(uintptr_t);
+  RSize = RoundUpToAlignment(RSize, llvm::alignOf<uint64_t>());
+  std::size_t Alignment = llvm::alignOf<uint64_t>();
+
+  void *P;
+
+#if defined(_MSC_VER)
+  P = _aligned_malloc(RSize, Alignment);
+  assert(P && "_aligned_malloc failed!");
+  if (!P) return 0;
+#else
+  int R = posix_memalign(&P, Alignment, RSize);
+  assert((R == 0) && "posix_memalign failed!");
+  if (R != 0) return 0;
+#endif
+
+  (void) std::memset(P, 0, RSize);
+
+  // Set a valid pointer to the address which will be returned
+  // by this operator. This will be a pointer to a MDNodeFwdDecl.
+  unsigned char *UC = static_cast<unsigned char*>(P);
+  MDNodeFwdDecl *MFD =
+    reinterpret_cast<MDNodeFwdDecl*>((UC + RSize) -
+        (Size + sizeof(ReplaceableMetadataImpl)));
+  MDNode *MN = static_cast<MDNode*>(MFD);
+  ReplaceableMetadataImpl *RMI = static_cast<ReplaceableMetadataImpl*>(MFD);
+
+  MDOperand *O = reinterpret_cast<MDOperand*>(MN);
+  MDOperand *MO;
+
+  for (MDOperand *E = O - NumOps; O != E; --O) {
+    MO = new (O - 1) MDOperand();
+    assert(MO && "MDOperand placement new failed!");
+  }
+
+  // We store the address of the aligned allocated buffer
+  // in the last extra element of the buffer. This address
+  // will be used by the corresponding operator delete to
+  // free the correct address.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+  *U = reinterpret_cast<uintptr_t>(P);
+  return MFD;
+}
+
+void MDNodeFwdDecl::operator delete(void *Mem) throw() {
+  MDNodeFwdDecl *MFD = reinterpret_cast<MDNodeFwdDecl*>(Mem);
+  ReplaceableMetadataImpl *RMI =
+    static_cast<ReplaceableMetadataImpl*>(MFD);
+  MDNode *MN = static_cast<MDNode*>(MFD);
+
+  std::size_t OSize = MN->getNumOperands() * sizeof(MDOperand);
+  OSize = RoundUpToAlignment(OSize, llvm::alignOf<uint64_t>());
+
+  MDOperand *O =
+    reinterpret_cast<MDOperand*>(reinterpret_cast<void*>(MN));
+  for (MDOperand *E = O - MN->getNumOperands(); O != E; --O) {
+    MDOperand *MO = (O - 1);
+    MO->~MDOperand();
+  }
+
+  // This is the address of the allocated buffer in the
+  // extra space allocated by operator new in RSize.
+  uintptr_t *U = reinterpret_cast<uintptr_t*>(O - 1);
+
+  // Do not perform a full canonical destructor sequence here because
+  // MDNodeFwdDecl's are being deleted by ReplaceableMetadataImpl's
+  // destructor, which gets called from MDNode::deleteTemporary().
+  std::free(reinterpret_cast<void*>(*U));
+}
+
+//===----------------------------------------------------------------------===//
 // NamedMDNode implementation.
 //
 
--- lib/Support/SmallVector.cpp	2012-08-21 17:11:07.000000000 -0700
+++ lib/Support/SmallVector.cpp	2015-08-26 21:28:23.352666372 -0700
@@ -11,9 +11,13 @@
 //
 //===----------------------------------------------------------------------===//
 
+#include "llvm/Support/MathExtras.h"
+#include "llvm/Support/raw_ostream.h"
 #include "llvm/ADT/SmallVector.h"
 using namespace llvm;
 
+#include <stdlib.h>
+
 /// grow_pod - This is an implementation of the grow() method which only works
 /// on POD-like datatypes and is out of line to reduce code duplication.
 void SmallVectorBase::grow_pod(void *FirstEl, size_t MinSizeInBytes,
@@ -23,15 +27,42 @@
   if (NewCapacityInBytes < MinSizeInBytes)
     NewCapacityInBytes = MinSizeInBytes;
 
+  NewCapacityInBytes =
+    llvm::RoundUpToAlignment(NewCapacityInBytes, llvm::alignOf<uint64_t>());
+
   void *NewElts;
   if (BeginX == FirstEl) {
-    NewElts = malloc(NewCapacityInBytes);
+    unsigned Alignment = llvm::alignOf<uint64_t>();
+#if defined(_MSC_VER)
+    NewElts = _aligned_malloc(Alignment, NewCapacityInBytes);
+    assert(NewElts && "_aligned_malloc failed!");
+#else
+    int R = posix_memalign(&NewElts, Alignment, NewCapacityInBytes);
+    assert((R == 0) && "posix_memalign failed!");
+#endif
+
+    assert(NewElts && "Invalid pointer after aligned allocation!");
+    (void) std::memset(NewElts, 0, NewCapacityInBytes);
 
     // Copy the elements over.  No need to run dtors on PODs.
-    memcpy(NewElts, this->BeginX, CurSizeBytes);
+    (void) std::memcpy(NewElts, this->BeginX, CurSizeBytes);
   } else {
     // If this wasn't grown from the inline copy, grow the allocated space.
-    NewElts = realloc(this->BeginX, NewCapacityInBytes);
+    unsigned Alignment = llvm::alignOf<uint64_t>();
+#if defined(_MSC_VER)
+    NewElts = _aligned_malloc(Alignment, NewCapacityInBytes);
+    assert(NewElts && "_aligned_malloc failed!");
+#else
+    int R = posix_memalign(&NewElts, Alignment, NewCapacityInBytes);
+    assert((R == 0) && "posix_memalign failed!");
+#endif
+
+    assert(NewElts && "Invalid pointer after aligned allocation!");
+    (void) std::memset(NewElts, 0, NewCapacityInBytes);
+
+    // Copy the elements over.  No need to run dtors on PODs.
+    (void) std::memcpy(NewElts, this->BeginX, CurSizeBytes);
+    std::free(this->BeginX);
   }
 
   this->EndX = (char*)NewElts+CurSizeBytes;
--- tools/clang/lib/AST/NestedNameSpecifier.cpp	2014-09-25 17:28:20.000000000 -0700
+++ tools/clang/lib/AST/NestedNameSpecifier.cpp	2015-08-26 08:27:36.324291508 -0700
@@ -437,20 +437,37 @@
               unsigned &BufferCapacity) {
     if (BufferSize + (End - Start) > BufferCapacity) {
       // Reallocate the buffer.
-      unsigned NewCapacity 
-      = std::max((unsigned)(BufferCapacity? BufferCapacity * 2 
-                            : sizeof(void*) * 2),
-                 (unsigned)(BufferSize + (End - Start)));
-      char *NewBuffer = static_cast<char *>(malloc(NewCapacity));
-      memcpy(NewBuffer, Buffer, BufferSize);
+      unsigned NewCapacity =
+        std::max((unsigned)(BufferCapacity? BufferCapacity * 2 
+              : sizeof(void*) * 2), (unsigned)(BufferSize + (End - Start)));
+      NewCapacity =
+        llvm::RoundUpToAlignment(NewCapacity, llvm::alignOf<uint64_t>());
+      unsigned Alignment = ((NewCapacity < 5) ? 4 : 8);
+      if (NewCapacity < Alignment)
+        NewCapacity = Alignment;
       
-      if (BufferCapacity)
+      char *NewBuffer;
+#if defined(_MSC_VER)
+      NewBuffer = _aligned_malloc((size_t) NewCapacity, (size_t) Alignment);
+      assert(NewBuffer && "_aligned_malloc failed!");
+#else
+      int R = posix_memalign((void**) &NewBuffer, Alignment, NewCapacity);
+
+      assert((R == 0) && "posix_memalign failed!");
+      assert(NewBuffer && "Memory allocation failed!");
+#endif
+
+      if ((Buffer != 0) && (BufferSize > 0))
+        (void) std::memcpy(NewBuffer, Buffer, BufferSize);
+
+      if ((Buffer != 0) && (BufferSize > 0))
         free(Buffer);
+
       Buffer = NewBuffer;
       BufferCapacity = NewCapacity;
     }
     
-    memcpy(Buffer + BufferSize, Start, End - Start);
+    (void) std::memcpy(Buffer + BufferSize, Start, End - Start);
     BufferSize += End-Start;
   }
   
